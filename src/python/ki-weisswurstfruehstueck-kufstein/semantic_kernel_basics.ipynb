{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Kernel with Azure OpenAI âš¡\n",
    "\n",
    "This notebook is a simple demonstration of how to use the [Semantic Kernel](https://learn.microsoft.com/semantic-kernel/overview/?WT.mc_id=AZ-MVP-5003203) with [Azure OpenAI](https://azure.microsoft.com/products/ai-services/openai-service?WT.mc_id=AZ-MVP-5003203). \n",
    "\n",
    "## Install requirements\n",
    "Make sure you have configured the necessary settings for the Azure OpenAI Connector. See the [documentation](https://github.com/microsoft/semantic-kernel/blob/main/python/README.md#openai--azure-openai-api-keys).\n",
    "\n",
    "We only need to install the Semantic Kernel SDK from pypi.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install semantic-kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "\n",
    "kernel = Kernel()\n",
    "service_id=\"chat-gpt\"\n",
    "\n",
    "kernel.add_service(\n",
    "  AzureChatCompletion(\n",
    "      service_id=service_id,\n",
    "  )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Plugins\n",
    "The following script will add all plugins from the `plugins_directory` to the kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "plugins_directory = \"Plugins\"\n",
    "azure_plugin = kernel.add_plugin(parent_directory=plugins_directory, plugin_name=\"AzurePlugin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the AzureCli Plugin "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await kernel.invoke(azure_plugin[\"AzureCliCommand\"], input=\"retrieve all azure open ai api keys\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Azure Advisor Plugin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_description=\"\"\"\n",
    "    The project is an e-commerce platform that needs to handle high traffic during seasonal sales. \n",
    "    It should be able to scale automatically, manage containerized microservices, and provide secure payment processing. \n",
    "    The application requires high availability across multiple regions with failover capabilities. \n",
    "    Cost optimization is a priority, but the solution should also ensure smooth handling of peak traffic. \n",
    "    The team prefers minimal infrastructure management but needs some control over deployment and scaling configurations.\n",
    "\"\"\"\n",
    "\n",
    "result = await kernel.invoke(azure_plugin[\"AzureAdvisor\"], input=project_description)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "project_description=\"\"\"\n",
    "    The project is a real-time notification system for a mobile app. \n",
    "    It needs to process events triggered by user activity and scale automatically based on demand. \n",
    "    The team wants to minimize infrastructure management and prefers a serverless solution with event-driven architecture. \n",
    "    The application should handle intermittent high loads but remain cost-efficient when usage is low. \n",
    "    Security and seamless integration with other Azure services, like storage and databases, are also important.\n",
    "\"\"\"\n",
    "\n",
    "result = await kernel.invoke(azure_plugin[\"AzureAdvisor\"], input=project_description)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add native code as a plugin\n",
    "The plugin described below allows us to **execute Azure CLI** commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "from semantic_kernel.functions import kernel_function\n",
    "\n",
    "class ExecuteAzureCliCommand:\n",
    "    \"\"\"\n",
    "    Description: This plugin is used to execute Azure CLI commands\n",
    "    \"\"\"\n",
    "\n",
    "    @kernel_function(\n",
    "        description=\"Execute Azure CLI command\",\n",
    "        name=\"ExecuteAzureCliCommand\",\n",
    "    )\n",
    "    def execute_azurecli_command (self, input: str) -> str:\n",
    "        \"\"\"\n",
    "        Execute Azure CLI command\n",
    "        \"\"\"\n",
    "        try:\n",
    "            command = input.replace(\"az\", \"\").strip() # remove az from the input\n",
    "            result = subprocess.run(['az'] + command.split(), capture_output=True, text=True, check=True, shell=True)\n",
    "\n",
    "            print(result.stdout)\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"Error executing Azure CLI command: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the native plugin to the kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "execute_azurecli_plugin = kernel.add_plugin(plugin=ExecuteAzureCliCommand(), plugin_name=\"ExecuteAzureCliCommand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execute_azurecli_fnc = execute_azurecli_plugin[\"ExecuteAzureCliCommand\"]\n",
    "azurecli_output = await execute_azurecli_fnc(kernel,input=\"account show\")\n",
    "print(azurecli_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Planner ðŸª„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.planners.function_calling_stepwise_planner import (\n",
    "    FunctionCallingStepwisePlanner,\n",
    "    FunctionCallingStepwisePlannerOptions,\n",
    ")\n",
    "\n",
    "question = \"List all ressource groups\"\n",
    "\n",
    "options = FunctionCallingStepwisePlannerOptions(\n",
    "    max_iterations=5,\n",
    "    max_tokens=4000,\n",
    ")\n",
    "\n",
    "planner = FunctionCallingStepwisePlanner(service_id=service_id, options=options)\n",
    "result = await planner.invoke(kernel, question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Chat history: {result.chat_history}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
