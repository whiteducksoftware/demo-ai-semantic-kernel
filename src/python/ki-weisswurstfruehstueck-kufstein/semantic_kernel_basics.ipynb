{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Kernel with Azure OpenAI âš¡\n",
    "\n",
    "This notebook is a simple demonstration of how to use the [Semantic Kernel](https://learn.microsoft.com/semantic-kernel/overview/?WT.mc_id=AZ-MVP-5003203) with [Azure OpenAI](https://azure.microsoft.com/products/ai-services/openai-service?WT.mc_id=AZ-MVP-5003203). \n",
    "\n",
    "## Install requirements\n",
    "Make sure you have configured the necessary settings for the Azure OpenAI Connector. See the [documentation](https://github.com/microsoft/semantic-kernel/blob/main/python/README.md#openai--azure-openai-api-keys).\n",
    "\n",
    "We only need to install the Semantic Kernel SDK from pypi.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting semantic-kernel\n",
      "  Using cached semantic_kernel-1.11.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting aiohttp~=3.8 (from semantic-kernel)\n",
      "  Downloading aiohttp-3.10.9-cp312-cp312-win_amd64.whl.metadata (7.8 kB)\n",
      "Collecting pydantic~=2.0 (from semantic-kernel)\n",
      "  Downloading pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n",
      "Collecting pydantic-settings~=2.0 (from semantic-kernel)\n",
      "  Using cached pydantic_settings-2.5.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting defusedxml~=0.7 (from semantic-kernel)\n",
      "  Using cached defusedxml-0.7.1-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Collecting azure-identity~=1.13 (from semantic-kernel)\n",
      "  Downloading azure_identity-1.18.0-py3-none-any.whl.metadata (81 kB)\n",
      "Collecting numpy>=1.26.0 (from semantic-kernel)\n",
      "  Downloading numpy-2.1.2-cp312-cp312-win_amd64.whl.metadata (59 kB)\n",
      "Collecting openai~=1.0 (from semantic-kernel)\n",
      "  Using cached openai-1.51.0-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting openapi_core<0.20,>=0.18 (from semantic-kernel)\n",
      "  Using cached openapi_core-0.19.4-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting opentelemetry-api~=1.24 (from semantic-kernel)\n",
      "  Using cached opentelemetry_api-1.27.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting opentelemetry-sdk~=1.24 (from semantic-kernel)\n",
      "  Using cached opentelemetry_sdk-1.27.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting prance~=23.6.21.0 (from semantic-kernel)\n",
      "  Using cached prance-23.6.21.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pybars4~=0.9 (from semantic-kernel)\n",
      "  Using cached pybars4-0.9.13-py3-none-any.whl\n",
      "Collecting jinja2~=3.1 (from semantic-kernel)\n",
      "  Using cached jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: nest-asyncio~=1.6 in d:\\source\\github\\whiteduck\\demo-ai-semantic-kernel\\.venv\\lib\\site-packages (from semantic-kernel) (1.6.0)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp~=3.8->semantic-kernel)\n",
      "  Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp~=3.8->semantic-kernel)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp~=3.8->semantic-kernel)\n",
      "  Using cached attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp~=3.8->semantic-kernel)\n",
      "  Using cached frozenlist-1.4.1-cp312-cp312-win_amd64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp~=3.8->semantic-kernel)\n",
      "  Downloading multidict-6.1.0-cp312-cp312-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting yarl<2.0,>=1.12.0 (from aiohttp~=3.8->semantic-kernel)\n",
      "  Downloading yarl-1.13.1-cp312-cp312-win_amd64.whl.metadata (52 kB)\n",
      "Collecting azure-core>=1.31.0 (from azure-identity~=1.13->semantic-kernel)\n",
      "  Downloading azure_core-1.31.0-py3-none-any.whl.metadata (39 kB)\n",
      "Collecting cryptography>=2.5 (from azure-identity~=1.13->semantic-kernel)\n",
      "  Downloading cryptography-43.0.1-cp39-abi3-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting msal>=1.30.0 (from azure-identity~=1.13->semantic-kernel)\n",
      "  Downloading msal-1.31.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting msal-extensions>=1.2.0 (from azure-identity~=1.13->semantic-kernel)\n",
      "  Downloading msal_extensions-1.2.0-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting typing-extensions>=4.0.0 (from azure-identity~=1.13->semantic-kernel)\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2~=3.1->semantic-kernel)\n",
      "  Using cached MarkupSafe-2.1.5-cp312-cp312-win_amd64.whl.metadata (3.1 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from openai~=1.0->semantic-kernel)\n",
      "  Downloading anyio-4.6.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai~=1.0->semantic-kernel)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai~=1.0->semantic-kernel)\n",
      "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai~=1.0->semantic-kernel)\n",
      "  Using cached jiter-0.5.0-cp312-none-win_amd64.whl.metadata (3.7 kB)\n",
      "Collecting sniffio (from openai~=1.0->semantic-kernel)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>4 (from openai~=1.0->semantic-kernel)\n",
      "  Using cached tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting isodate (from openapi_core<0.20,>=0.18->semantic-kernel)\n",
      "  Using cached isodate-0.6.1-py2.py3-none-any.whl.metadata (9.6 kB)\n",
      "Collecting jsonschema<5.0.0,>=4.18.0 (from openapi_core<0.20,>=0.18->semantic-kernel)\n",
      "  Using cached jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting jsonschema-path<0.4.0,>=0.3.1 (from openapi_core<0.20,>=0.18->semantic-kernel)\n",
      "  Using cached jsonschema_path-0.3.3-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting more-itertools (from openapi_core<0.20,>=0.18->semantic-kernel)\n",
      "  Using cached more_itertools-10.5.0-py3-none-any.whl.metadata (36 kB)\n",
      "Collecting openapi-schema-validator<0.7.0,>=0.6.0 (from openapi_core<0.20,>=0.18->semantic-kernel)\n",
      "  Using cached openapi_schema_validator-0.6.2-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting openapi-spec-validator<0.8.0,>=0.7.1 (from openapi_core<0.20,>=0.18->semantic-kernel)\n",
      "  Using cached openapi_spec_validator-0.7.1-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting parse (from openapi_core<0.20,>=0.18->semantic-kernel)\n",
      "  Using cached parse-1.20.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting werkzeug (from openapi_core<0.20,>=0.18->semantic-kernel)\n",
      "  Downloading werkzeug-3.0.4-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-api~=1.24->semantic-kernel)\n",
      "  Using cached Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting importlib-metadata<=8.4.0,>=6.0 (from opentelemetry-api~=1.24->semantic-kernel)\n",
      "  Downloading importlib_metadata-8.4.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.48b0 (from opentelemetry-sdk~=1.24->semantic-kernel)\n",
      "  Using cached opentelemetry_semantic_conventions-0.48b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting chardet>=3.0 (from prance~=23.6.21.0->semantic-kernel)\n",
      "  Using cached chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting ruamel.yaml>=0.17.10 (from prance~=23.6.21.0->semantic-kernel)\n",
      "  Using cached ruamel.yaml-0.18.6-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting requests>=2.25 (from prance~=23.6.21.0->semantic-kernel)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: six~=1.15 in d:\\source\\github\\whiteduck\\demo-ai-semantic-kernel\\.venv\\lib\\site-packages (from prance~=23.6.21.0->semantic-kernel) (1.16.0)\n",
      "Requirement already satisfied: packaging>=21.3 in d:\\source\\github\\whiteduck\\demo-ai-semantic-kernel\\.venv\\lib\\site-packages (from prance~=23.6.21.0->semantic-kernel) (24.1)\n",
      "Collecting PyMeta3>=0.5.1 (from pybars4~=0.9->semantic-kernel)\n",
      "  Using cached PyMeta3-0.5.1-py3-none-any.whl\n",
      "Collecting annotated-types>=0.6.0 (from pydantic~=2.0->semantic-kernel)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.23.4 (from pydantic~=2.0->semantic-kernel)\n",
      "  Downloading pydantic_core-2.23.4-cp312-none-win_amd64.whl.metadata (6.7 kB)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings~=2.0->semantic-kernel)\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting idna>=2.8 (from anyio<5,>=3.5.0->openai~=1.0->semantic-kernel)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting cffi>=1.12 (from cryptography>=2.5->azure-identity~=1.13->semantic-kernel)\n",
      "  Downloading cffi-1.17.1-cp312-cp312-win_amd64.whl.metadata (1.6 kB)\n",
      "Collecting wrapt<2,>=1.10 (from deprecated>=1.2.6->opentelemetry-api~=1.24->semantic-kernel)\n",
      "  Using cached wrapt-1.16.0-cp312-cp312-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting certifi (from httpx<1,>=0.23.0->openai~=1.0->semantic-kernel)\n",
      "  Downloading certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai~=1.0->semantic-kernel)\n",
      "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai~=1.0->semantic-kernel)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting zipp>=0.5 (from importlib-metadata<=8.4.0,>=6.0->opentelemetry-api~=1.24->semantic-kernel)\n",
      "  Downloading zipp-3.20.2-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel)\n",
      "  Using cached jsonschema_specifications-2023.12.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel)\n",
      "  Using cached referencing-0.35.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel)\n",
      "  Using cached rpds_py-0.20.0-cp312-none-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting PyYAML>=5.1 (from jsonschema-path<0.4.0,>=0.3.1->openapi_core<0.20,>=0.18->semantic-kernel)\n",
      "  Using cached PyYAML-6.0.2-cp312-cp312-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting pathable<0.5.0,>=0.4.1 (from jsonschema-path<0.4.0,>=0.3.1->openapi_core<0.20,>=0.18->semantic-kernel)\n",
      "  Using cached pathable-0.4.3-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting PyJWT<3,>=1.0.0 (from PyJWT[crypto]<3,>=1.0.0->msal>=1.30.0->azure-identity~=1.13->semantic-kernel)\n",
      "  Downloading PyJWT-2.9.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting portalocker<3,>=1.4 (from msal-extensions>=1.2.0->azure-identity~=1.13->semantic-kernel)\n",
      "  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting rfc3339-validator (from openapi-schema-validator<0.7.0,>=0.6.0->openapi_core<0.20,>=0.18->semantic-kernel)\n",
      "  Using cached rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting lazy-object-proxy<2.0.0,>=1.7.1 (from openapi-spec-validator<0.8.0,>=0.7.1->openapi_core<0.20,>=0.18->semantic-kernel)\n",
      "  Using cached lazy_object_proxy-1.10.0-cp312-cp312-win_amd64.whl.metadata (8.1 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests>=2.25->prance~=23.6.21.0->semantic-kernel)\n",
      "  Using cached charset_normalizer-3.3.2-cp312-cp312-win_amd64.whl.metadata (34 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.25->prance~=23.6.21.0->semantic-kernel)\n",
      "  Downloading urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.17.10->prance~=23.6.21.0->semantic-kernel)\n",
      "  Using cached ruamel.yaml.clib-0.2.8-cp312-cp312-win_amd64.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: colorama in d:\\source\\github\\whiteduck\\demo-ai-semantic-kernel\\.venv\\lib\\site-packages (from tqdm>4->openai~=1.0->semantic-kernel) (0.4.6)\n",
      "Collecting pycparser (from cffi>=1.12->cryptography>=2.5->azure-identity~=1.13->semantic-kernel)\n",
      "  Using cached pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Requirement already satisfied: pywin32>=226 in d:\\source\\github\\whiteduck\\demo-ai-semantic-kernel\\.venv\\lib\\site-packages (from portalocker<3,>=1.4->msal-extensions>=1.2.0->azure-identity~=1.13->semantic-kernel) (307)\n",
      "Using cached semantic_kernel-1.11.0-py3-none-any.whl (472 kB)\n",
      "Downloading aiohttp-3.10.9-cp312-cp312-win_amd64.whl (379 kB)\n",
      "Downloading azure_identity-1.18.0-py3-none-any.whl (187 kB)\n",
      "Using cached defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Using cached jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "Downloading numpy-2.1.2-cp312-cp312-win_amd64.whl (12.6 MB)\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ----------------------------------- ---- 11.0/12.6 MB 52.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.6/12.6 MB 52.4 MB/s eta 0:00:00\n",
      "Using cached openai-1.51.0-py3-none-any.whl (383 kB)\n",
      "Using cached openapi_core-0.19.4-py3-none-any.whl (103 kB)\n",
      "Using cached opentelemetry_api-1.27.0-py3-none-any.whl (63 kB)\n",
      "Using cached opentelemetry_sdk-1.27.0-py3-none-any.whl (110 kB)\n",
      "Using cached opentelemetry_semantic_conventions-0.48b0-py3-none-any.whl (149 kB)\n",
      "Using cached prance-23.6.21.0-py3-none-any.whl (36 kB)\n",
      "Downloading pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
      "Downloading pydantic_core-2.23.4-cp312-none-win_amd64.whl (1.9 MB)\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.9/1.9 MB 53.4 MB/s eta 0:00:00\n",
      "Using cached pydantic_settings-2.5.2-py3-none-any.whl (26 kB)\n",
      "Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl (14 kB)\n",
      "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading anyio-4.6.0-py3-none-any.whl (89 kB)\n",
      "Using cached attrs-24.2.0-py3-none-any.whl (63 kB)\n",
      "Downloading azure_core-1.31.0-py3-none-any.whl (197 kB)\n",
      "Using cached chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "Downloading cryptography-43.0.1-cp39-abi3-win_amd64.whl (3.1 MB)\n",
      "   ---------------------------------------- 0.0/3.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 3.1/3.1 MB 59.8 MB/s eta 0:00:00\n",
      "Using cached Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached frozenlist-1.4.1-cp312-cp312-win_amd64.whl (50 kB)\n",
      "Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "Downloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
      "Downloading importlib_metadata-8.4.0-py3-none-any.whl (26 kB)\n",
      "Using cached jiter-0.5.0-cp312-none-win_amd64.whl (189 kB)\n",
      "Using cached jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
      "Using cached jsonschema_path-0.3.3-py3-none-any.whl (14 kB)\n",
      "Using cached MarkupSafe-2.1.5-cp312-cp312-win_amd64.whl (17 kB)\n",
      "Downloading msal-1.31.0-py3-none-any.whl (113 kB)\n",
      "Downloading msal_extensions-1.2.0-py3-none-any.whl (19 kB)\n",
      "Downloading multidict-6.1.0-cp312-cp312-win_amd64.whl (28 kB)\n",
      "Using cached openapi_schema_validator-0.6.2-py3-none-any.whl (8.8 kB)\n",
      "Using cached openapi_spec_validator-0.7.1-py3-none-any.whl (38 kB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached ruamel.yaml-0.18.6-py3-none-any.whl (117 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Downloading yarl-1.13.1-cp312-cp312-win_amd64.whl (111 kB)\n",
      "Using cached isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
      "Using cached more_itertools-10.5.0-py3-none-any.whl (60 kB)\n",
      "Using cached parse-1.20.2-py2.py3-none-any.whl (20 kB)\n",
      "Downloading werkzeug-3.0.4-py3-none-any.whl (227 kB)\n",
      "Downloading certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "Downloading cffi-1.17.1-cp312-cp312-win_amd64.whl (181 kB)\n",
      "Using cached charset_normalizer-3.3.2-cp312-cp312-win_amd64.whl (100 kB)\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached jsonschema_specifications-2023.12.1-py3-none-any.whl (18 kB)\n",
      "Using cached lazy_object_proxy-1.10.0-cp312-cp312-win_amd64.whl (27 kB)\n",
      "Using cached pathable-0.4.3-py3-none-any.whl (9.6 kB)\n",
      "Downloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
      "Downloading PyJWT-2.9.0-py3-none-any.whl (22 kB)\n",
      "Using cached PyYAML-6.0.2-cp312-cp312-win_amd64.whl (156 kB)\n",
      "Using cached referencing-0.35.1-py3-none-any.whl (26 kB)\n",
      "Using cached rpds_py-0.20.0-cp312-none-win_amd64.whl (214 kB)\n",
      "Using cached ruamel.yaml.clib-0.2.8-cp312-cp312-win_amd64.whl (115 kB)\n",
      "Downloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "Using cached wrapt-1.16.0-cp312-cp312-win_amd64.whl (37 kB)\n",
      "Downloading zipp-3.20.2-py3-none-any.whl (9.2 kB)\n",
      "Using cached rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Using cached pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Installing collected packages: PyMeta3, parse, zipp, wrapt, urllib3, typing-extensions, tqdm, sniffio, ruamel.yaml.clib, rpds-py, rfc3339-validator, PyYAML, python-dotenv, PyJWT, pycparser, pybars4, portalocker, pathable, numpy, multidict, more-itertools, MarkupSafe, lazy-object-proxy, jiter, isodate, idna, h11, frozenlist, distro, defusedxml, charset-normalizer, chardet, certifi, attrs, annotated-types, aiohappyeyeballs, yarl, werkzeug, ruamel.yaml, requests, referencing, pydantic-core, jinja2, importlib-metadata, httpcore, deprecated, cffi, anyio, aiosignal, pydantic, prance, opentelemetry-api, jsonschema-specifications, jsonschema-path, httpx, cryptography, azure-core, aiohttp, pydantic-settings, opentelemetry-semantic-conventions, openai, jsonschema, opentelemetry-sdk, openapi-schema-validator, msal, openapi-spec-validator, msal-extensions, openapi_core, azure-identity, semantic-kernel\n",
      "Successfully installed MarkupSafe-2.1.5 PyJWT-2.9.0 PyMeta3-0.5.1 PyYAML-6.0.2 aiohappyeyeballs-2.4.3 aiohttp-3.10.9 aiosignal-1.3.1 annotated-types-0.7.0 anyio-4.6.0 attrs-24.2.0 azure-core-1.31.0 azure-identity-1.18.0 certifi-2024.8.30 cffi-1.17.1 chardet-5.2.0 charset-normalizer-3.3.2 cryptography-43.0.1 defusedxml-0.7.1 deprecated-1.2.14 distro-1.9.0 frozenlist-1.4.1 h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 idna-3.10 importlib-metadata-8.4.0 isodate-0.6.1 jinja2-3.1.4 jiter-0.5.0 jsonschema-4.23.0 jsonschema-path-0.3.3 jsonschema-specifications-2023.12.1 lazy-object-proxy-1.10.0 more-itertools-10.5.0 msal-1.31.0 msal-extensions-1.2.0 multidict-6.1.0 numpy-2.1.2 openai-1.51.0 openapi-schema-validator-0.6.2 openapi-spec-validator-0.7.1 openapi_core-0.19.4 opentelemetry-api-1.27.0 opentelemetry-sdk-1.27.0 opentelemetry-semantic-conventions-0.48b0 parse-1.20.2 pathable-0.4.3 portalocker-2.10.1 prance-23.6.21.0 pybars4-0.9.13 pycparser-2.22 pydantic-2.9.2 pydantic-core-2.23.4 pydantic-settings-2.5.2 python-dotenv-1.0.1 referencing-0.35.1 requests-2.32.3 rfc3339-validator-0.1.4 rpds-py-0.20.0 ruamel.yaml-0.18.6 ruamel.yaml.clib-0.2.8 semantic-kernel-1.11.0 sniffio-1.3.1 tqdm-4.66.5 typing-extensions-4.12.2 urllib3-2.2.3 werkzeug-3.0.4 wrapt-1.16.0 yarl-1.13.1 zipp-3.20.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install semantic-kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "\n",
    "kernel = Kernel()\n",
    "service_id=\"chat-gpt\"\n",
    "\n",
    "kernel.add_service(\n",
    "  AzureChatCompletion(\n",
    "      service_id=service_id,\n",
    "  )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Plugins\n",
    "The following script will add all plugins from the `plugins_directory` to the kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "plugins_directory = \"Plugins\"\n",
    "kubernetesPlugin = kernel.add_plugin(parent_directory=plugins_directory, plugin_name=\"KubernetesPlugin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the KubectlPrompt Plugin "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```sh\n",
      "kubectl get namespaces\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "result = await kernel.invoke(kubernetesPlugin[\"KubectlPrompt\"], input=\"list all namespace\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the KubeMatch Plugin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided project description and the factors to consider, Kubernetes appears to be a highly suitable platform for deploying the high-traffic e-commerce platform. Here's a detailed assessment:\n",
      "\n",
      "### Scalability\n",
      "**Requirement:** The project needs to scale dynamically to handle seasonal peaks in user traffic.\n",
      "**Kubernetes Fit:** Kubernetes excels in dynamic scaling. It supports horizontal pod autoscaling, which can automatically adjust the number of running pods based on CPU utilization or other select metrics. This makes it ideal for handling fluctuating traffic patterns.\n",
      "\n",
      "### Manageability\n",
      "**Requirement:** Centralized platform to manage containers.\n",
      "**Kubernetes Fit:** Kubernetes provides a centralized platform for managing containerized applications. It offers features like namespaces, labels, and annotations to organize and manage resources efficiently. Tools like the Kubernetes Dashboard and third-party solutions (e.g., Rancher) further enhance manageability.\n",
      "\n",
      "### Microservices Architecture\n",
      "**Requirement:** The project is based on microservices.\n",
      "**Kubernetes Fit:** Kubernetes is designed to support microservices architectures. It allows for the independent deployment, scaling, and management of each microservice. Service discovery, load balancing, and rolling updates are built-in features that align well with microservices.\n",
      "\n",
      "### Deployment Complexity\n",
      "**Requirement:** Consider the complexity involved in deploying and maintaining Kubernetes.\n",
      "**Kubernetes Fit:** While Kubernetes can be complex to set up and maintain, the benefits it offers in terms of scalability, manageability, and orchestration often outweigh the initial complexity. Managed Kubernetes services like Google Kubernetes Engine (GKE), Amazon EKS, and Azure AKS can simplify deployment and maintenance.\n",
      "\n",
      "### Team Expertise\n",
      "**Requirement:** The team is experienced in containerized environments.\n",
      "**Kubernetes Fit:** Given that the team already has experience with containerized environments, the transition to Kubernetes should be smoother. However, some additional training may be required to master Kubernetes-specific concepts and tools. The learning curve is there, but it is manageable given the team's existing expertise.\n",
      "\n",
      "### Security Requirements\n",
      "**Requirement:** Robust security measures.\n",
      "**Kubernetes Fit:** Kubernetes offers robust security features, including role-based access control (RBAC), network policies, and secrets management. These features can be configured to meet the specific security needs of the project.\n",
      "\n",
      "### Resource Utilization\n",
      "**Requirement:** Efficient resource management.\n",
      "**Kubernetes Fit:** Kubernetes is designed for efficient resource utilization. It supports resource requests and limits, which help in optimizing the use of CPU and memory. Kubernetes also provides tools for monitoring and managing resource usage.\n",
      "\n",
      "### Vendor Lock-in and Flexibility\n",
      "**Requirement:** Avoid vendor lock-in and maintain flexibility.\n",
      "**Kubernetes Fit:** Kubernetes is an open-source platform supported by all major cloud providers, which reduces the risk of vendor lock-in. It offers the flexibility to run on various environments, including on-premises, hybrid, and multi-cloud setups.\n",
      "\n",
      "### Recommendation\n",
      "Given the project's requirements for dynamic scaling, manageability, microservices architecture, and the team's existing expertise in containerized environments, Kubernetes is a highly appropriate choice. It offers robust orchestration capabilities, efficient resource management, and strong security features, all of which align well with the needs of a high-traffic e-commerce platform.\n",
      "\n",
      "While there is some complexity involved in deploying and maintaining Kubernetes, the benefits it provides in terms of scalability, manageability, and flexibility make it a worthwhile investment. Managed Kubernetes services can further reduce the operational burden, allowing the team to focus more on developing and optimizing the e-commerce platform.\n",
      "\n",
      "**Conclusion:** Kubernetes is a suitable and recommended platform for deploying the described high-traffic e-commerce project.\n"
     ]
    }
   ],
   "source": [
    "goodFit=\"\"\"\n",
    "This project involves developing a high-traffic e-commerce platform that expects dynamic scaling and high availability to handle seasonal peaks in user traffic. \n",
    "The architecture is based on microservices, each responsible for different aspects such as user authentication, product catalog, and payment processing. \n",
    "The team is experienced in containerized environments and requires a solution that allows for efficient deployment, scaling, and management of services, with robust orchestration capabilities.\n",
    "\"\"\"\n",
    "\n",
    "result = await kernel.invoke(kubernetesPlugin[\"KubeMatch\"], input=goodFit)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided project description and the factors to consider, here is an assessment of whether Kubernetes is a suitable platform for deployment:\n",
      "\n",
      "### Scalability\n",
      "- **Assessment**: The project has minimal scalability requirements and is expected to have a stable and predictable load.\n",
      "- **Conclusion**: Kubernetes is designed for dynamic scaling, which is not necessary for this project. Therefore, Kubernetes may be overkill for the scalability needs of this project.\n",
      "\n",
      "### Manageability\n",
      "- **Assessment**: While Kubernetes offers centralized management for containers, the project is small-scale and involves a simple monolithic architecture.\n",
      "- **Conclusion**: The benefits of Kubernetes' centralized management are less significant for a small-scale project with minimal complexity.\n",
      "\n",
      "### Microservices Architecture\n",
      "- **Assessment**: The project is built with a monolithic architecture.\n",
      "- **Conclusion**: Kubernetes excels in managing microservices architectures, but this project does not follow that pattern. Therefore, Kubernetes may not be the best fit.\n",
      "\n",
      "### Deployment Complexity\n",
      "- **Assessment**: Deploying and maintaining a Kubernetes environment involves significant complexity.\n",
      "- **Conclusion**: Given the simplicity of the project, the overhead of setting up and maintaining Kubernetes is not justified.\n",
      "\n",
      "### Team Expertise\n",
      "- **Assessment**: The team lacks experience with containerization and Kubernetes.\n",
      "- **Conclusion**: The learning curve and training costs to get the team up to speed with Kubernetes would be high and are not justified for this simple project.\n",
      "\n",
      "### Security Requirements\n",
      "- **Assessment**: Kubernetes offers robust security features, but the project description does not specify any advanced security needs.\n",
      "- **Conclusion**: The security features of Kubernetes may not be necessary for this project, and simpler solutions could suffice.\n",
      "\n",
      "### Resource Utilization\n",
      "- **Assessment**: Kubernetes is efficient in managing resources, but this efficiency is more beneficial for larger, more complex projects.\n",
      "- **Conclusion**: For a small-scale project, the resource management capabilities of Kubernetes may not provide significant advantages.\n",
      "\n",
      "### Vendor Lock-in and Flexibility\n",
      "- **Assessment**: Kubernetes offers flexibility and reduces vendor lock-in.\n",
      "- **Conclusion**: While this is a benefit, it is less relevant for a small-scale, internal tool with minimal complexity.\n",
      "\n",
      "### Recommendation\n",
      "Given the factors above, Kubernetes does not appear to be an appropriate choice for this project. The complexity, overhead, and learning curve associated with Kubernetes are not justified for a small-scale, monolithic application with minimal scalability requirements and a team lacking containerization experience.\n",
      "\n",
      "### Alternative Recommendations\n",
      "- **Docker Compose**: For containerization without the complexity of Kubernetes, Docker Compose could be a simpler alternative.\n",
      "- **Traditional Deployment**: Given the simplicity of the project, traditional deployment methods (e.g., deploying directly on VMs or physical servers) might be the most straightforward and cost-effective approach.\n",
      "- **Platform-as-a-Service (PaaS)**: Consider using a PaaS solution like Heroku or Google App Engine, which can simplify deployment and management without the need for deep containerization expertise.\n",
      "\n",
      "In summary, Kubernetes is not recommended for this project. Simpler deployment solutions would be more appropriate and cost-effective.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "badFit=\"\"\"\n",
    "This project is a small-scale internal tool for automating office inventory management, expected to have a stable and predictable load with minimal scalability requirements. \n",
    "The application is built with a simple, monolithic architecture and will be deployed on a few servers. \n",
    "The team lacks experience with containerization and Kubernetes, and the simplicity of the project does not justify the overhead and complexity of implementing a Kubernetes environment.\n",
    "\"\"\"\n",
    "\n",
    "result = await kernel.invoke(kubernetesPlugin[\"KubeMatch\"], input=badFit)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add native code as a plugin\n",
    "The plugin described below allows us to **execute kubectl** commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "from semantic_kernel.functions import kernel_function\n",
    "\n",
    "class ExecuteKubectlPlugin:\n",
    "    \"\"\"\n",
    "    Description: This plugin is used to execute kubectl commands\n",
    "    \"\"\"\n",
    "\n",
    "    @kernel_function(\n",
    "        description=\"Execute kubectl command\",\n",
    "        name=\"ExecuteKubectl\",\n",
    "    )\n",
    "    def execute_kubectl_command (self, input: str) -> str:\n",
    "        \"\"\"\n",
    "        Execute kubectl command\n",
    "        \"\"\"\n",
    "        try:\n",
    "            command = input.replace(\"kubectl\", \"\").strip() # remove kubectl from the input\n",
    "            result = subprocess.run(['kubectl'] + command.split(), capture_output=True, text=True, check=True)\n",
    "\n",
    "            print(result.stdout)\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"Error executing kubectl command: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the native plugin to the kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "execute_kubectl_plugin = kernel.add_plugin(plugin=ExecuteKubectlPlugin(), plugin_name=\"ExecuteKubectlPlugin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kubernetes control plane is running at https://kufstein-demo-dns-iedm2rw6.hcp.germanywestcentral.azmk8s.io:443\n",
      "CoreDNS is running at https://kufstein-demo-dns-iedm2rw6.hcp.germanywestcentral.azmk8s.io:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\n",
      "Metrics-server is running at https://kufstein-demo-dns-iedm2rw6.hcp.germanywestcentral.azmk8s.io:443/api/v1/namespaces/kube-system/services/https:metrics-server:/proxy\n",
      "\n",
      "To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "execute_kubectl_fnc = execute_kubectl_plugin[\"ExecuteKubectl\"]\n",
    "kubectl_output = await execute_kubectl_fnc(kernel,input=\"kubectl cluster-info\")\n",
    "print(kubectl_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Planner ðŸª„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.planners.function_calling_stepwise_planner import (\n",
    "    FunctionCallingStepwisePlanner,\n",
    "    FunctionCallingStepwisePlannerOptions,\n",
    ")\n",
    "\n",
    "question = \"list all namepsaces\"\n",
    "\n",
    "options = FunctionCallingStepwisePlannerOptions(\n",
    "    max_iterations=10,\n",
    "    max_tokens=4000,\n",
    ")\n",
    "\n",
    "planner = FunctionCallingStepwisePlanner(service_id=service_id, options=options)\n",
    "result = await planner.invoke(kernel, question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Chat history: {result.chat_history}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
